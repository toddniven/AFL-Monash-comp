{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "pd.set_option(\"display.max_columns\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proxy settings when using cntlm\n",
    "http_proxy  = \"http://localhost:3128\"\n",
    "https_proxy = \"https://localhost:3128\"\n",
    "\n",
    "proxyDict = { \n",
    "              \"http\"  : http_proxy, \n",
    "              \"https\" : https_proxy, \n",
    "            }\n",
    "proxyDict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'Richmond': 'richmond',\n",
    "    'West Coast': 'westcoast',\n",
    "    'Sydney': 'swans',\n",
    "    'Adelaide': 'adelaide',\n",
    "    'Geelong': 'geelong',\n",
    "    'Greater Western Sydney': 'gws',\n",
    "    'Melbourne': 'melbourne',\n",
    "    'Port Adelaide': 'padelaide',\n",
    "    'Collingwood': 'collingwood',\n",
    "    'Hawthorn': 'hawthorn',\n",
    "    'Essendon': 'essendon',\n",
    "    'Western Bulldogs': 'bullldogs',\n",
    "    'St Kilda': 'stkilda',\n",
    "    'North Melbourne': 'kangaroos',\n",
    "    'Kangaroos' : 'kangaroos',\n",
    "    'Fremantle': 'fremantle',\n",
    "    'Brisbane Lions': 'brisbanel',\n",
    "    'Gold Coast': 'goldcoast',\n",
    "    'Carlton': 'carlton'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep.team_history import History\n",
    "team_df = History(mapping, proxyDict).generate_team_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History(mapping, proxyDict).generate_game_data('training-all/', team_df)\n",
    "History(mapping, proxyDict).generate_game_data_ha('training-hva/', team_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2789, 33)\n",
      "(2789,)\n",
      "Wins vs losses 0.577626389386877\n"
     ]
    }
   ],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for i in range(1,16):\n",
    "#     if i not in [3,6,7,8]: # remove 2016,2013,2012,2011\n",
    "    X = np.concatenate([\n",
    "        np.load('training-all/training-'+str(2019-i)+'.npy'),\n",
    "        np.load('training-hva/training-'+str(2019-i)+'.npy')[:,1:] #remove the rnd column\n",
    "                ], axis=1)\n",
    "    mask = np.isnan(X).any(axis=1)\n",
    "    index = np.where(mask==True)[0][0] ## X8 has a row containing nulls\n",
    "    X = np.delete(X, index, 0)\n",
    "    X_list.append(X)\n",
    "\n",
    "    y = np.load('training-all/results-'+str(2019-i)+'.npy')\n",
    "    y = np.delete(y, index, 0)\n",
    "    y_list.append(y)\n",
    "    \n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.concatenate(y_list, axis=0)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print('Wins vs losses',np.sum(y)/float(len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rnd</th>\n",
       "      <th>h_F_mean</th>\n",
       "      <th>h_F_std</th>\n",
       "      <th>h_A_mean</th>\n",
       "      <th>h_A_std</th>\n",
       "      <th>h_M_mean</th>\n",
       "      <th>h_M_std</th>\n",
       "      <th>h_W_sum</th>\n",
       "      <th>h_perc</th>\n",
       "      <th>a_F_mean</th>\n",
       "      <th>a_F_std</th>\n",
       "      <th>a_A_mean</th>\n",
       "      <th>a_A_std</th>\n",
       "      <th>a_M_mean</th>\n",
       "      <th>a_M_std</th>\n",
       "      <th>a_W_sum</th>\n",
       "      <th>a_perc</th>\n",
       "      <th>h_F_mean_hva</th>\n",
       "      <th>h_F_std_hva</th>\n",
       "      <th>h_A_mean_hva</th>\n",
       "      <th>h_A_std_hva</th>\n",
       "      <th>h_M_mean_hva</th>\n",
       "      <th>h_M_std_hva</th>\n",
       "      <th>h_W_sum_hva</th>\n",
       "      <th>h_perc_hva</th>\n",
       "      <th>a_F_mean_hva</th>\n",
       "      <th>a_F_std_hva</th>\n",
       "      <th>a_A_mean_hva</th>\n",
       "      <th>a_A_std_hva</th>\n",
       "      <th>a_M_mean_hva</th>\n",
       "      <th>a_M_std_hva</th>\n",
       "      <th>a_W_sum_hva</th>\n",
       "      <th>a_perc_hva</th>\n",
       "      <th>F_mean</th>\n",
       "      <th>F_std</th>\n",
       "      <th>A_mean</th>\n",
       "      <th>A_std</th>\n",
       "      <th>M_mean</th>\n",
       "      <th>M_std</th>\n",
       "      <th>W_sum</th>\n",
       "      <th>perc</th>\n",
       "      <th>F_mean_hva</th>\n",
       "      <th>F_std_hva</th>\n",
       "      <th>A_mean_hva</th>\n",
       "      <th>A_std_hva</th>\n",
       "      <th>M_mean_hva</th>\n",
       "      <th>M_std_hva</th>\n",
       "      <th>W_sum_hva</th>\n",
       "      <th>perc_hva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>101.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953052</td>\n",
       "      <td>109.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.190217</td>\n",
       "      <td>121.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.273684</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.008547</td>\n",
       "      <td>0.926941</td>\n",
       "      <td>1.025424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.157609</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800737</td>\n",
       "      <td>1.262890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>101.666667</td>\n",
       "      <td>27.577164</td>\n",
       "      <td>100.666667</td>\n",
       "      <td>16.263456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.263456</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.009934</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>101.333333</td>\n",
       "      <td>4.949747</td>\n",
       "      <td>-18.666667</td>\n",
       "      <td>4.949747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>111.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.211957</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>1.229839</td>\n",
       "      <td>1.281609</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993421</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.053571</td>\n",
       "      <td>-1.300000</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.237983</td>\n",
       "      <td>1.420915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>14.275854</td>\n",
       "      <td>74.166667</td>\n",
       "      <td>39.274674</td>\n",
       "      <td>30.833333</td>\n",
       "      <td>39.274674</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.415730</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>26.780590</td>\n",
       "      <td>82.166667</td>\n",
       "      <td>21.335417</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>21.335417</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.018256</td>\n",
       "      <td>111.00</td>\n",
       "      <td>13.435029</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>44.00</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.656716</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>25.455844</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>29.698485</td>\n",
       "      <td>-17.666667</td>\n",
       "      <td>29.698485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>1.254980</td>\n",
       "      <td>1.608696</td>\n",
       "      <td>0.533067</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.902637</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>1.840821</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>20.555556</td>\n",
       "      <td>-2.490566</td>\n",
       "      <td>1.840821</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.390349</td>\n",
       "      <td>2.080900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>100.555556</td>\n",
       "      <td>14.169888</td>\n",
       "      <td>75.555556</td>\n",
       "      <td>33.070272</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>33.070272</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.330882</td>\n",
       "      <td>65.111111</td>\n",
       "      <td>19.455076</td>\n",
       "      <td>93.444444</td>\n",
       "      <td>11.624328</td>\n",
       "      <td>-28.333333</td>\n",
       "      <td>11.624328</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.696790</td>\n",
       "      <td>110.75</td>\n",
       "      <td>9.539392</td>\n",
       "      <td>58.5</td>\n",
       "      <td>43.405069</td>\n",
       "      <td>52.25</td>\n",
       "      <td>43.405069</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.893162</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>7.023769</td>\n",
       "      <td>-41.000000</td>\n",
       "      <td>7.023769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>1.544369</td>\n",
       "      <td>2.089623</td>\n",
       "      <td>0.728339</td>\n",
       "      <td>1.362770</td>\n",
       "      <td>0.808561</td>\n",
       "      <td>0.622340</td>\n",
       "      <td>2.844919</td>\n",
       "      <td>6.179740</td>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-1.274390</td>\n",
       "      <td>2.844919</td>\n",
       "      <td>6.179740</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.910021</td>\n",
       "      <td>3.357684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>97.307692</td>\n",
       "      <td>18.372410</td>\n",
       "      <td>72.076923</td>\n",
       "      <td>32.980251</td>\n",
       "      <td>25.230769</td>\n",
       "      <td>32.980251</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.350053</td>\n",
       "      <td>88.307692</td>\n",
       "      <td>19.942341</td>\n",
       "      <td>70.230769</td>\n",
       "      <td>15.023214</td>\n",
       "      <td>18.076923</td>\n",
       "      <td>15.023214</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.257393</td>\n",
       "      <td>109.60</td>\n",
       "      <td>7.804913</td>\n",
       "      <td>62.2</td>\n",
       "      <td>39.306488</td>\n",
       "      <td>47.40</td>\n",
       "      <td>39.306488</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.762058</td>\n",
       "      <td>93.166667</td>\n",
       "      <td>17.672012</td>\n",
       "      <td>68.166667</td>\n",
       "      <td>13.935566</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>13.935566</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.366748</td>\n",
       "      <td>1.101916</td>\n",
       "      <td>1.176386</td>\n",
       "      <td>0.921276</td>\n",
       "      <td>0.441654</td>\n",
       "      <td>1.026287</td>\n",
       "      <td>0.912469</td>\n",
       "      <td>2.195286</td>\n",
       "      <td>2.820588</td>\n",
       "      <td>1.395745</td>\n",
       "      <td>1.896000</td>\n",
       "      <td>2.195286</td>\n",
       "      <td>2.820588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.073692</td>\n",
       "      <td>1.289234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rnd    h_F_mean    h_F_std    h_A_mean    h_A_std   h_M_mean    h_M_std  \\\n",
       "0   3.0  101.500000   0.000000  106.500000   0.000000  -5.000000   0.000000   \n",
       "1   4.0  101.666667  27.577164  100.666667  16.263456   1.000000  16.263456   \n",
       "2   7.0  105.000000  14.275854   74.166667  39.274674  30.833333  39.274674   \n",
       "3  10.0  100.555556  14.169888   75.555556  33.070272  25.000000  33.070272   \n",
       "4  15.0   97.307692  18.372410   72.076923  32.980251  25.230769  32.980251   \n",
       "\n",
       "   h_W_sum    h_perc    a_F_mean    a_F_std    a_A_mean    a_A_std   a_M_mean  \\\n",
       "0      1.0  0.953052  109.500000   0.000000   92.000000   0.000000  17.500000   \n",
       "1      2.0  1.009934   82.666667   5.656854  101.333333   4.949747 -18.666667   \n",
       "2      5.0  1.415730   83.666667  26.780590   82.166667  21.335417   1.500000   \n",
       "3      7.0  1.330882   65.111111  19.455076   93.444444  11.624328 -28.333333   \n",
       "4     10.0  1.350053   88.307692  19.942341   70.230769  15.023214  18.076923   \n",
       "\n",
       "     a_M_std  a_W_sum    a_perc  h_F_mean_hva  h_F_std_hva  h_A_mean_hva  \\\n",
       "0   0.000000      2.0  1.190217        121.00     0.000000          95.0   \n",
       "1   4.949747      0.0  0.815789        111.50     0.000000          92.0   \n",
       "2  21.335417      3.0  1.018256        111.00    13.435029          67.0   \n",
       "3  11.624328      2.0  0.696790        110.75     9.539392          58.5   \n",
       "4  15.023214     10.0  1.257393        109.60     7.804913          62.2   \n",
       "\n",
       "   h_A_std_hva  h_M_mean_hva  h_M_std_hva  h_W_sum_hva  h_perc_hva  \\\n",
       "0     0.000000         26.00     0.000000          0.0    1.273684   \n",
       "1     0.000000         19.50     0.000000          2.0    1.211957   \n",
       "2     4.242641         44.00     4.242641          3.0    1.656716   \n",
       "3    43.405069         52.25    43.405069          4.0    1.893162   \n",
       "4    39.306488         47.40    39.306488          5.0    1.762058   \n",
       "\n",
       "   a_F_mean_hva  a_F_std_hva  a_A_mean_hva  a_A_std_hva  a_M_mean_hva  \\\n",
       "0    118.000000     0.000000    117.000000     0.000000      1.000000   \n",
       "1     87.000000     0.000000    102.000000     0.000000    -15.000000   \n",
       "2     69.000000    25.455844     86.666667    29.698485    -17.666667   \n",
       "3     53.000000     7.000000     94.000000     7.023769    -41.000000   \n",
       "4     93.166667    17.672012     68.166667    13.935566     25.000000   \n",
       "\n",
       "   a_M_std_hva  a_W_sum_hva  a_perc_hva    F_mean     F_std    A_mean  \\\n",
       "0     0.000000          0.0    1.008547  0.926941  1.025424  0.000000   \n",
       "1     0.000000          0.0    0.852941  1.229839  1.281609  4.875000   \n",
       "2    29.698485          1.0    0.796154  1.254980  1.608696  0.533067   \n",
       "3     7.023769          0.0    0.563830  1.544369  2.089623  0.728339   \n",
       "4    13.935566          6.0    1.366748  1.101916  1.176386  0.921276   \n",
       "\n",
       "      A_std    M_mean     M_std     W_sum      perc  F_mean_hva  F_std_hva  \\\n",
       "0  0.000000  1.157609  0.811966  0.000000  0.000000   -0.285714  26.000000   \n",
       "1  0.000000  0.993421  0.901961  3.285714  0.000000   -0.053571  -1.300000   \n",
       "2  0.527778  0.902637  0.773077  1.840821  0.142857   20.555556  -2.490566   \n",
       "3  1.362770  0.808561  0.622340  2.844919  6.179740   -0.882353  -1.274390   \n",
       "4  0.441654  1.026287  0.912469  2.195286  2.820588    1.395745   1.896000   \n",
       "\n",
       "   A_mean_hva  A_std_hva  M_mean_hva  M_std_hva  W_sum_hva  perc_hva  \n",
       "0    0.000000   0.000000    0.500000   0.000000   0.800737  1.262890  \n",
       "1    3.285714   0.000000    0.000000   0.000000   1.237983  1.420915  \n",
       "2    1.840821   0.142857    1.666667   3.000000   1.390349  2.080900  \n",
       "3    2.844919   6.179740    3.500000   0.000000   1.910021  3.357684  \n",
       "4    2.195286   2.820588    1.000000   0.833333   1.073692  1.289234  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_prep.feature_eng import Features\n",
    "training_cols = Features().training_cols()\n",
    "pd.DataFrame(Features().div_cols(X_list[0]), columns=training_cols).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupting!\n",
      "Season 2018\n",
      "Bayes CV search took 7.65 seconds for 50 candidates parameter settings.\n",
      "val. score: 66.85034890767076\n",
      "test score: 26.04779536224933\n",
      "XGBClassifier(base_score=0.57574568288854, booster='gbtree',\n",
      "       colsample_bylevel=0.7769115900139626,\n",
      "       colsample_bynode=0.12953003411010086,\n",
      "       colsample_bytree=0.17714429798092454, gamma=0,\n",
      "       learning_rate=0.028680448385152265, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=283, n_jobs=-1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.19542027703869053, reg_lambda=0.7285954159368625,\n",
      "       scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=0.10597699210128961)\n",
      "\n",
      "Interrupting!\n",
      "Season 2017\n",
      "Bayes CV search took 2.39 seconds for 50 candidates parameter settings.\n",
      "val. score: 66.48768260054484\n",
      "test score: 10.030569388528312\n",
      "XGBClassifier(base_score=0.57574568288854, booster='gbtree',\n",
      "       colsample_bylevel=0.4413131759124075,\n",
      "       colsample_bynode=0.5085823345504136,\n",
      "       colsample_bytree=0.9449977515922252, gamma=0,\n",
      "       learning_rate=0.012317133743473095, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=None, n_estimators=211, n_jobs=-1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0.2313290166811915, reg_lambda=0.9408401511986718,\n",
      "       scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=0.5348518734845704)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from training.training import Training\n",
    "Training(50, 65).train(X_list, y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>W_sum_hva</th>\n",
       "      <td>0.049328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_mean</th>\n",
       "      <td>0.039885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perc_hva</th>\n",
       "      <td>0.036358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_mean_hva</th>\n",
       "      <td>0.035771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F_mean</th>\n",
       "      <td>0.033839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_std</th>\n",
       "      <td>0.033577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_M_mean</th>\n",
       "      <td>0.032085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_perc</th>\n",
       "      <td>0.029295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h_A_mean</th>\n",
       "      <td>0.028742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_M_mean</th>\n",
       "      <td>0.028151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            importance\n",
       "W_sum_hva     0.049328\n",
       "M_mean        0.039885\n",
       "perc_hva      0.036358\n",
       "M_mean_hva    0.035771\n",
       "F_mean        0.033839\n",
       "M_std         0.033577\n",
       "h_M_mean      0.032085\n",
       "h_perc        0.029295\n",
       "h_A_mean      0.028742\n",
       "a_M_mean      0.028151"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def averagingImp(models=[]):\n",
    "    predictions = np.column_stack([\n",
    "        model.feature_importances_ for model in models\n",
    "    ])\n",
    "    return np.mean(predictions, axis=1)\n",
    "\n",
    "imp = pd.DataFrame(data=averagingImp(best_models),\n",
    "             index=training_cols, \n",
    "             columns=['importance']).sort_values(by=['importance'], ascending=False)\n",
    "imp.iloc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averagingModels(X, models=[]):\n",
    "    predictions = np.column_stack([\n",
    "        model.predict_proba(X)[:,1] for model in models\n",
    "    ])\n",
    "    return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11fc01b00>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12.5,4))\n",
    "line_height = 2\n",
    "data = averagingModels(X_train,best_models)\n",
    "x = plt.hist(data, bins='auto', density=True, facecolor='green', alpha=0.5)\n",
    "\n",
    "plt.vlines(np.percentile(data, 5), 0, line_height, linestyle=\"--\", colors='green', label=\"5%\")\n",
    "plt.vlines(np.percentile(data, 50), 0, line_height, linestyle=\"--\", colors='red', label=\"50%\")\n",
    "plt.vlines(np.percentile(data, 95), 0, line_height, linestyle=\"--\", colors='blue', label=\"95%\")\n",
    "plt.xlabel('Probability')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_score</th>\n",
       "      <th>booster</th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>colsample_bynode</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_delta_step</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>missing</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>nthread</th>\n",
       "      <th>objective</th>\n",
       "      <th>random_state</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>scale_pos_weight</th>\n",
       "      <th>seed</th>\n",
       "      <th>silent</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.680524</td>\n",
       "      <td>0.451782</td>\n",
       "      <td>0.447147</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028247</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519922</td>\n",
       "      <td>0.585741</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.313918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.454218</td>\n",
       "      <td>0.268137</td>\n",
       "      <td>0.978430</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>141</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>0.898282</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.957945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.553358</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.851059</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>201</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879758</td>\n",
       "      <td>0.888103</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.160439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.107928</td>\n",
       "      <td>0.190706</td>\n",
       "      <td>0.592649</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036763</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>130</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.735182</td>\n",
       "      <td>0.392457</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.535468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.305340</td>\n",
       "      <td>0.641205</td>\n",
       "      <td>0.599234</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>395</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.210949</td>\n",
       "      <td>0.478085</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.716786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.526666</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.279787</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011277</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>306</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175568</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.108579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.926885</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.922799</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013320</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>187</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695967</td>\n",
       "      <td>0.600300</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.299203</td>\n",
       "      <td>0.223769</td>\n",
       "      <td>0.520360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012589</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>368</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750903</td>\n",
       "      <td>0.905496</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.102233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.708440</td>\n",
       "      <td>0.270919</td>\n",
       "      <td>0.677547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>337</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.856258</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.412864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258166</td>\n",
       "      <td>0.440758</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007214</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>342</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467363</td>\n",
       "      <td>0.354359</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.840542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.288188</td>\n",
       "      <td>0.569395</td>\n",
       "      <td>0.156495</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017764</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>216</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.316943</td>\n",
       "      <td>0.851641</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.351460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.355433</td>\n",
       "      <td>0.576490</td>\n",
       "      <td>0.936621</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>480</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253432</td>\n",
       "      <td>0.927502</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.238570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.564415</td>\n",
       "      <td>0.745192</td>\n",
       "      <td>0.614139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>316</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448358</td>\n",
       "      <td>0.794795</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.375786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.388883</td>\n",
       "      <td>0.843645</td>\n",
       "      <td>0.644269</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>324</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956469</td>\n",
       "      <td>0.974655</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.394827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.575746</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.577291</td>\n",
       "      <td>0.421939</td>\n",
       "      <td>0.208757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>491</td>\n",
       "      <td>-1</td>\n",
       "      <td>None</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273306</td>\n",
       "      <td>0.892245</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.653661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    base_score booster  colsample_bylevel  colsample_bynode  colsample_bytree  \\\n",
       "0     0.575746  gbtree           0.680524          0.451782          0.447147   \n",
       "1     0.575746  gbtree           0.454218          0.268137          0.978430   \n",
       "2     0.575746  gbtree           0.553358          0.100000          0.851059   \n",
       "3     0.575746  gbtree           0.107928          0.190706          0.592649   \n",
       "4     0.575746  gbtree           0.305340          0.641205          0.599234   \n",
       "5     0.575746  gbtree           0.526666          0.100000          0.279787   \n",
       "6     0.575746  gbtree           0.926885          0.100000          0.922799   \n",
       "7     0.575746  gbtree           0.299203          0.223769          0.520360   \n",
       "8     0.575746  gbtree           0.708440          0.270919          0.677547   \n",
       "9     0.575746  gbtree           1.000000          0.258166          0.440758   \n",
       "10    0.575746  gbtree           0.288188          0.569395          0.156495   \n",
       "11    0.575746  gbtree           0.355433          0.576490          0.936621   \n",
       "12    0.575746  gbtree           0.564415          0.745192          0.614139   \n",
       "13    0.575746  gbtree           0.388883          0.843645          0.644269   \n",
       "14    0.575746  gbtree           0.577291          0.421939          0.208757   \n",
       "\n",
       "    gamma  learning_rate  max_delta_step  max_depth  min_child_weight missing  \\\n",
       "0       0       0.028247               0          3                 1    None   \n",
       "1       0       0.019809               0          5                 1    None   \n",
       "2       0       0.021332               0          3                 1    None   \n",
       "3       0       0.036763               0          4                 1    None   \n",
       "4       0       0.010123               0          3                 1    None   \n",
       "5       0       0.011277               0          5                 1    None   \n",
       "6       0       0.013320               0          3                 1    None   \n",
       "7       0       0.012589               0          3                 1    None   \n",
       "8       0       0.008973               0          4                 1    None   \n",
       "9       0       0.007214               0          4                 1    None   \n",
       "10      0       0.017764               0          4                 1    None   \n",
       "11      0       0.004990               0          3                 1    None   \n",
       "12      0       0.005636               0          4                 1    None   \n",
       "13      0       0.007694               0          3                 1    None   \n",
       "14      0       0.010671               0          4                 1    None   \n",
       "\n",
       "    n_estimators  n_jobs nthread        objective  random_state  reg_alpha  \\\n",
       "0            100      -1    None  binary:logistic             0   0.519922   \n",
       "1            141      -1    None  binary:logistic             0   0.962804   \n",
       "2            201      -1    None  binary:logistic             0   0.879758   \n",
       "3            130      -1    None  binary:logistic             0   0.735182   \n",
       "4            395      -1    None  binary:logistic             0   0.210949   \n",
       "5            306      -1    None  binary:logistic             0   0.000000   \n",
       "6            187      -1    None  binary:logistic             0   0.695967   \n",
       "7            368      -1    None  binary:logistic             0   0.750903   \n",
       "8            337      -1    None  binary:logistic             0   0.856258   \n",
       "9            342      -1    None  binary:logistic             0   0.467363   \n",
       "10           216      -1    None  binary:logistic             0   0.316943   \n",
       "11           480      -1    None  binary:logistic             0   0.253432   \n",
       "12           316      -1    None  binary:logistic             0   0.448358   \n",
       "13           324      -1    None  binary:logistic             0   0.956469   \n",
       "14           491      -1    None  binary:logistic             0   0.273306   \n",
       "\n",
       "    reg_lambda  scale_pos_weight  seed  silent  subsample  \n",
       "0     0.585741                 1  None    True   0.313918  \n",
       "1     0.898282                 1  None    True   0.957945  \n",
       "2     0.888103                 1  None    True   0.160439  \n",
       "3     0.392457                 1  None    True   0.535468  \n",
       "4     0.478085                 1  None    True   0.716786  \n",
       "5     0.175568                 1  None    True   0.108579  \n",
       "6     0.600300                 1  None    True   0.100000  \n",
       "7     0.905496                 1  None    True   0.102233  \n",
       "8     0.009805                 1  None    True   0.412864  \n",
       "9     0.354359                 1  None    True   0.840542  \n",
       "10    0.851641                 1  None    True   0.351460  \n",
       "11    0.927502                 1  None    True   0.238570  \n",
       "12    0.794795                 1  None    True   0.375786  \n",
       "13    0.974655                 1  None    True   0.394827  \n",
       "14    0.892245                 1  None    True   0.653661  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for model in best_models:\n",
    "    rows.append(model.get_params())\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d719674/dev/code/AFL-Monash-comp/data_prep/web_scraping.py:35: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 35 of the file /Users/d719674/dev/code/AFL-Monash-comp/data_prep/web_scraping.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(r.text, \"html\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Sydney', 'Collingwood'],\n",
       " ['Hawthorn', 'Port Adelaide'],\n",
       " ['Western Bulldogs', 'North Melbourne'],\n",
       " ['Adelaide', 'West Coast'],\n",
       " ['Gold Coast', 'Geelong'],\n",
       " ['Richmond', 'Essendon'],\n",
       " ['Melbourne', 'Greater Western Sydney'],\n",
       " ['St Kilda', 'Carlton'],\n",
       " ['Fremantle', 'Brisbane Lions']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_prep.web_scraping import Scrape\n",
    "\n",
    "games = []\n",
    "start = 110\n",
    "for i in range(start,start+9):\n",
    "    games.append(Scrape(mapping, proxyDict).scrape_game(i))\n",
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep.scoring import Scoring\n",
    "scoring = Scoring(mapping, proxyDict).score_data(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep.feature_eng import Features\n",
    "scoring_enr = Features().div_cols(scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>prob_avg</th>\n",
       "      <th>prob_med</th>\n",
       "      <th>prob_std</th>\n",
       "      <th>prob_max</th>\n",
       "      <th>prob_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>Collingwood</td>\n",
       "      <td>0.36563626</td>\n",
       "      <td>0.36634937</td>\n",
       "      <td>0.026151553</td>\n",
       "      <td>0.41000614</td>\n",
       "      <td>0.30985445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hawthorn</td>\n",
       "      <td>Port Adelaide</td>\n",
       "      <td>0.55493045</td>\n",
       "      <td>0.54920745</td>\n",
       "      <td>0.025378436</td>\n",
       "      <td>0.60855323</td>\n",
       "      <td>0.50598794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Western Bulldogs</td>\n",
       "      <td>North Melbourne</td>\n",
       "      <td>0.7655727</td>\n",
       "      <td>0.7679378</td>\n",
       "      <td>0.02065708</td>\n",
       "      <td>0.801389</td>\n",
       "      <td>0.7212015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>0.6487142</td>\n",
       "      <td>0.6538974</td>\n",
       "      <td>0.027225422</td>\n",
       "      <td>0.6912513</td>\n",
       "      <td>0.59796065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gold Coast</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>0.38297558</td>\n",
       "      <td>0.37539524</td>\n",
       "      <td>0.031649</td>\n",
       "      <td>0.4444556</td>\n",
       "      <td>0.3305094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Richmond</td>\n",
       "      <td>Essendon</td>\n",
       "      <td>0.64548874</td>\n",
       "      <td>0.65625054</td>\n",
       "      <td>0.027971305</td>\n",
       "      <td>0.69787747</td>\n",
       "      <td>0.5867932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Greater Western Sydney</td>\n",
       "      <td>0.3152276</td>\n",
       "      <td>0.30426827</td>\n",
       "      <td>0.031621356</td>\n",
       "      <td>0.38042012</td>\n",
       "      <td>0.27615812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>St Kilda</td>\n",
       "      <td>Carlton</td>\n",
       "      <td>0.6620133</td>\n",
       "      <td>0.65932333</td>\n",
       "      <td>0.028806102</td>\n",
       "      <td>0.7092106</td>\n",
       "      <td>0.6114993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fremantle</td>\n",
       "      <td>Brisbane Lions</td>\n",
       "      <td>0.6193788</td>\n",
       "      <td>0.61204815</td>\n",
       "      <td>0.02519435</td>\n",
       "      <td>0.6671486</td>\n",
       "      <td>0.56915736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               home                    away    prob_avg    prob_med  \\\n",
       "0            Sydney             Collingwood  0.36563626  0.36634937   \n",
       "1          Hawthorn           Port Adelaide  0.55493045  0.54920745   \n",
       "2  Western Bulldogs         North Melbourne   0.7655727   0.7679378   \n",
       "3          Adelaide              West Coast   0.6487142   0.6538974   \n",
       "4        Gold Coast                 Geelong  0.38297558  0.37539524   \n",
       "5          Richmond                Essendon  0.64548874  0.65625054   \n",
       "6         Melbourne  Greater Western Sydney   0.3152276  0.30426827   \n",
       "7          St Kilda                 Carlton   0.6620133  0.65932333   \n",
       "8         Fremantle          Brisbane Lions   0.6193788  0.61204815   \n",
       "\n",
       "      prob_std    prob_max    prob_min  \n",
       "0  0.026151553  0.41000614  0.30985445  \n",
       "1  0.025378436  0.60855323  0.50598794  \n",
       "2   0.02065708    0.801389   0.7212015  \n",
       "3  0.027225422   0.6912513  0.59796065  \n",
       "4     0.031649   0.4444556   0.3305094  \n",
       "5  0.027971305  0.69787747   0.5867932  \n",
       "6  0.031621356  0.38042012  0.27615812  \n",
       "7  0.028806102   0.7092106   0.6114993  \n",
       "8   0.02519435   0.6671486  0.56915736  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modelStats(X, models=[]):\n",
    "    predictions = np.column_stack([\n",
    "        model.predict_proba(X)[:,1] for model in models\n",
    "    ])\n",
    "    return [np.mean(predictions, axis=1), np.median(predictions, axis=1), np.std(predictions, axis=1), \n",
    "            np.max(predictions, axis=1), np.min(predictions, axis=1)]\n",
    "arr = np.c_[ games, modelStats(scoring_enr,best_models)[0],\n",
    "           modelStats(scoring_enr,best_models)[1],modelStats(scoring_enr,best_models)[2],\n",
    "            modelStats(scoring_enr,best_models)[3], modelStats(scoring_enr,best_models)[4]] \n",
    "pd.DataFrame(arr,columns=['home','away','prob_avg', 'prob_med', 'prob_std', 'prob_max', 'prob_min'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "for i in range(len(best_models)):\n",
    "    dump(best_models[i], 'models/model'+str(i)+'.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "best_models = []\n",
    "for i in range(15):\n",
    "    best_models.append(load('models/model'+str(i)+'.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
